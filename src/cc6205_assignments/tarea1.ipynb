{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbrMqMPyncTC"
      },
      "source": [
        "# **Tarea 1 - CC6205 Natural Language Processing üìö**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1HFX-9PpxF9"
      },
      "source": [
        "Bienvenid@s a la primera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te√≥ricos de las primeras semanas de clases, enfocado principalmente en ***Information Retrieval (IR)*** y ***Vector Space Models***. Si a√∫n no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "La tarea consta de una parte te√≥rica que busca evaluar conceptos vistos en clases. Seguido por una parte pr√°ctica con el f√≠n de introducirlos a la programaci√≥n en Python enfocada en NLP. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJshpe1yrKJr"
      },
      "source": [
        "## **1 - Preguntas te√≥ricas üìï** ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBEDKXBPoA7w"
      },
      "source": [
        "Las siguientes celdas contienen preguntas acerca del contenido visto en clases y en el material del curso.  Contestar cada pregunta en su celda correspondiente y **no extenderse m√°s de 100 palabras** . üôè"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNJPR1kMrw9R"
      },
      "source": [
        "**Pregunta 1: ¬øPor qu√© el an√°lisis del lenguaje humano es una tarea compleja? Mencione dos razones seg√∫n lo visto en clases.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlTBYHEptdde"
      },
      "source": [
        "> Porque las reglas que conforman el lenguaje son dif√≠ciles de entender y describir, haci√©ndonos buenos usuarios pero malos entendedores del lenguaje. Entre las razones que lo hacen dif√≠cil se encuentra la propiedad **discreta**, o que no se puede inferir el significado de una palabra por medio de sus letras; y la propiedad **dispersa**, o la capacidad del lenguaje de combinar palabras para formar nuevos significados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVMXilrYsiSZ"
      },
      "source": [
        "**Pregunta 2: ¬øCu√°les son las diferencias entre usar Deep learning y Machine Learning cl√°sico (empirismo) para un problema de NLP? Ejemplifique con alguna task.** Puede utilizar ChatGPT (debe indicarlo) para generar la respuesta y luego debe indicar si la respuesta entregada por ChatGPT es correcta o no. Mencione por qu√© seg√∫n lo visto en clases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXWMzpTtBZL"
      },
      "source": [
        "> Machine Learning cl√°sico necesita de una persona que detalla de antemano cuales son las caracter√≠sticas a utilizar. Por otra parte, el Deep Learning extrae caracter√≠sticas adem√°s de entrenar un modelo, sin dar a conocer cuales son estas caracter√≠sticas. Esto resulta en un modelo de caja negra, donde se pierde la interpretabilidad de lo que ocurre.\n",
        ">\n",
        "> Una task de ejemplo puede ser el an√°lisis de sentimiento. Por medio de Deep Learning una red neuronal se encarga de encontrar las caracter√≠sticas y entrenar un modelo, mientras que con ML cl√°sico (por ejemplo SVM) se deben introducir de forma manual las caracter√≠sticas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXc4XuVG7Loa"
      },
      "source": [
        " **Pregunta 3: Seg√∫n las primeras clases, ¬øQu√© m√©todo cl√°sico nos permite rankear las similitudes existentes entre documentos?, ¬øC√≥mo son las representaciones que genera y problemas que podr√≠an experimentar estas soluciones simples?** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtaQ_aVE8LhH"
      },
      "source": [
        "> Se puede rankear la similitud entre documentos usando el m√©todo de similiaridad coseno. Las representaciones que genera son vectoriales.\n",
        ">\n",
        "> Al estar basado en un modelo vectorial de frecuencia de palabras, no considera el contexto que pueda tener un documento. Esto puede generar problemas ya que dos documentos con palabras distintas pueden indicar algo similar y el modelo no lo identificar√≠a correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKNDNy047tcY"
      },
      "source": [
        "**Pregunta 4: Usted se encuentra realizando un modelo de clasificaci√≥n de sentimientos con texto, su jefe le se√±ala que debe eliminar las palabras mas comunes para obtener una mejor clasificaci√≥n. ¬øQu√© palabras le se√±ala que elimine su jefe?, ¬øes acaso esto una buena idea?.** Puede utilizar ChatGPT (debe indicarlo) para generar la respuesta y luego debe indicar si la respuesta entregada por ChatGPT es correcta o no. Mencione por qu√© seg√∫n lo visto en clases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRe4QaGS8MqY"
      },
      "source": [
        "> Se se√±ala que elimine las Stopwords, las cuales son t√©rminos que ocurren con alta frecuencia y que no aportan a la sem√°ntica. Estas stopwords suelen ser art√≠culos, pronombres, preposiciones y conjunciones.\n",
        ">\n",
        "> Se debe tomar en cuenta que el uso de stopwords no es recomendable en todas las tasks. Por ejemplo, para la traducci√≥n se requiere contar con todas esas palabras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPkWmrmLHWnQ"
      },
      "source": [
        "**Pregunta 5: Acorde al paper [A Vector Space Model for automatic indexing](https://dl.acm.org/doi/pdf/10.1145/361219.361220) un documento, $D_i$, puede ser definido formalmente como una tupla de t√©rminos, $(d_{i1}, d_{i2}, ..., d_{in})$, donde $d_{ij}$ representa el peso del j-esimo t√©rmino. En clase vieron algunas formas medir los pesos de estos t√©rminos. Mencione cuales fueron y sus ventajas y desventajas.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLqRTW08SzDN"
      },
      "source": [
        "> El peso de los t√©rminos en los documentos puede ser medido en base a frecuencia. Entre las formas de medir la frecuencia se encuentran:\n",
        ">\n",
        "> - TF: el peso de un t√©rmino es su cantidad de apariciones, dividido por la cantidad del t√©rmino con m√°s apariciones. Como ventaja evita dar m√°s peso a t√©rminos de documentos m√°s largos, y su desventaja es que no toma en cuenta la importancia de t√©rminos poco frecuentes.\n",
        ">\n",
        "> - TF-IDF: considera la frecuencia de un t√©rmino en un documento y su frecuencia inversa en todos los documentos. Al dar m√°s peso a t√©rminos de poca frecuencia tiene la ventaja de capturar su informaci√≥n, aunque es computacionalmente m√°s costoso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fpsz2pQt8x5"
      },
      "source": [
        "## **2 - Preguntas pr√°cticas üíª** ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YB92kQXspvbR"
      },
      "source": [
        "Esta segunda secci√≥n incluye ejercicios de programaci√≥n ü§ô. Leer atentamente las instrucciones entregadas a continuaci√≥n para facilitar el proceso de revisi√≥n de sus trabajos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PosWgWgRxHKp"
      },
      "source": [
        "**Instrucciones:**\n",
        "\n",
        "- Escribe tu c√≥digo entre las lineas de comentarios **### Aqu√≠ inicia tu c√≥digo ###** y **### Aqu√≠ termina tu c√≥digo ###**.\n",
        "- Cuando el ejercicio incluya un bloque llamado ***Test***, comprueba que el resultado de la ejecuci√≥n coincida con el resultado esperado.\n",
        "- Recuerde siempre mantener buenas pr√°cticas de c√≥digo.\n",
        "- Est√° permitido s√≥lo utilizar las librer√≠as importadas antes del Ejercicio 1.\n",
        "- **Recordar** que: *Documento = Oraci√≥n. Dataset = Corpus. Vocabulario = Tokens*.\n",
        "- El **orden de los resultados** pueden variar dependiendo de su m√°quina, pero los valores de los resultados son los mismos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBrmFHXhqUww"
      },
      "source": [
        "**Ejemplo:** Implemente una funci√≥n **`hello_world()`** que imprima en pantalla `\"Hello World\"`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tu7cIsawyJHx"
      },
      "outputs": [],
      "source": [
        "def hello_world():\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    print(\"Hello World\")\n",
        "    ### Aqu√≠ termina tu c√≥digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6klw12lwbW"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac-WMk2dyQbp",
        "outputId": "9030f89c-ed23-4f5e-e317-9153250b150e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "hello_world()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIoiAMxtyUjQ"
      },
      "source": [
        "***Resultado esperado***: \n",
        "<table>\n",
        "    <tr> \n",
        "        <td> Hello World </td> \n",
        "    </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlPyrPXiH0l4"
      },
      "source": [
        "Estas son las librer√≠as permitidas. Si quieren utilizar alguna librer√≠a adicional, pueden realizar la consulta a trav√©s de Discord. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CtP6Emjo1kF0"
      },
      "outputs": [],
      "source": [
        "import codecs\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Bibliotecas a√±adidas\n",
        "from functools import reduce\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSN4bBoY2Td4"
      },
      "source": [
        "**Ejercicio 1 - *Tokenizaci√≥n*** \n",
        "\n",
        "En el primer ejercicio veremos la dificultad üò® de tokenizar textos no estructurados, destacando la importancia de tener librer√≠as que realicen este trabajo. \n",
        "\n",
        "El archivo adjunto al enunciado de la tarea contiene la letra de una canci√≥n del marcianeke üëΩ. Utilice este texto para realizar su primera tokenizaci√≥n y ver qu√© tan bien funciona su funci√≥n. \n",
        "\n",
        "Ejecute el c√≥digo a continuaci√≥n para cargar el ejemplo. Recuerde realizar la modificaci√≥n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnNUYlWo21g4",
        "outputId": "6e65fa21-a0f6-4324-d5cb-21643f79ad2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Brr\n",
            "Marcianeke\n",
            "Vamo' a estar con Pailita\n",
            "Dimelo m√°\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar (brr)\n",
            "Tussi, keta quiere' mezclar\n",
            "Dimelo m√°\n",
            "\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta pura quiere' mezclar\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "\n",
            "Esperame que ahora entro yo\n",
            "Y lo que pide yo lo traje\n",
            "No visto de traje\n",
            "Puro corte calle, no de maquillaje\n",
            "Pronto coronamos y nos vamo' de viaje\n",
            "Tanto hit que hago que lo' culo bajen\n",
            "Ella se va de shopping\n",
            "Sale positivo si se hace el doping\n",
            "Baila twerk con un poco de popping\n",
            "Los fardos en el bot√≠n\n",
            "\n",
            "Si quieren letra llamen pa' mi booking\n",
            "Generando, sigo en la m√≠a lowkey\n",
            "Cooking en el estudio con tu woman\n",
            "Tanto whisky, pisco que hasta lo' vecinos toman\n",
            "Si se tiran pa' aca puede que la arena coman\n",
            "Ja, en el chanteo titulado sin diploma\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "Di-dimelo m√°\n",
            "\n",
            "Ah, pe-peligrosa\n",
            "Quiero ver como perreando me acosa\n",
            "Eso de atra' con el Gucci me lo roza\n",
            "Tengo tussi del naranjo me aburrio el rosa\n",
            "Capaz que tosa con el blunt\n",
            "Sprite con Flemibron\n",
            "Louis Vuitton, le quito la polera Champion\n",
            "A tu pretendiente con la fory lo espanto\n",
            "Puro perro, le doy de comer Champion Dog\n",
            "Ese toto lo corono yo\n",
            "La movie en play no hay stop\n",
            "Flow de sobra no hay stock\n",
            "Me la topo en la disco queda en shock\n",
            "My love, rica en las redes y en persona\n",
            "No usa Photoshop\n",
            "La llevo a comprar blone' al growshop\n",
            "En ropa interior los do'\n",
            "Me roza su vicky con mi boxer Top\n",
            "Dimelo m√°\n",
            "Ando en busca de una cri\n",
            "minal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta quiere' mezclar\n",
            "Dimelo m√°\n",
            "\n",
            "Ando en busca de una criminal (ah, ah)\n",
            "Esa que el gatillo le gusta jalar (rata-ta)\n",
            "Que le guste flotar y fumar\n",
            "Tussi, keta pura quiere' mezclar\n",
            "Marcianeke, Pailita\n",
            "Young Varas\n"
          ]
        }
      ],
      "source": [
        "text = codecs.open('../../data/marcianeke.txt', 'r', 'UTF-8').read()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIaOYzMk3v1X"
      },
      "source": [
        "Implementen una funci√≥n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Son libres de elegir la forma de tokenizar mientras no utilicen librer√≠as con tokenizadores ya implementados. Pueden utilizar la librer√≠a **re** importada para trabajar s√≠mbolos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dl42-hgIhqB"
      },
      "source": [
        "Ejemplo de uso:\n",
        "\n",
        "`get_tokens('Este es un ejemplo de prueba.')` \n",
        "\n",
        "Nos entregar√≠a:\n",
        "\n",
        "`['Este', 'es', 'un', 'ejemplo', 'de', 'prueba', '.']`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IF1RcIwq4G2x"
      },
      "outputs": [],
      "source": [
        "def get_tokens(text: str) -> list[str]:\n",
        "    \"\"\"Transforma el input en una lista de tokens\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    text : str\n",
        "        Texto a tokenizar\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    list[str]\n",
        "        Lista de tokens\n",
        "    \"\"\"\n",
        "    ### Inicio del c√≥digo ###\n",
        "\n",
        "\n",
        "    pattern = r\"\\s+|([^\\w\\s])\"\n",
        "    tokens = list(filter(None, re.split(pattern, text))) # Filtra todos los 'None'\n",
        "    return tokens\n",
        "\n",
        "    ### Fin del c√≥digo ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqlSpefv4_EH",
        "outputId": "a2b49fc3-e267-4e6d-eaed-7b11f358df9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Brr',\n",
              " 'Marcianeke',\n",
              " 'Vamo',\n",
              " \"'\",\n",
              " 'a',\n",
              " 'estar',\n",
              " 'con',\n",
              " 'Pailita',\n",
              " 'Dimelo',\n",
              " 'm√°',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " '(',\n",
              " 'brr',\n",
              " ')',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'm√°',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Esperame',\n",
              " 'que',\n",
              " 'ahora',\n",
              " 'entro',\n",
              " 'yo',\n",
              " 'Y',\n",
              " 'lo',\n",
              " 'que',\n",
              " 'pide',\n",
              " 'yo',\n",
              " 'lo',\n",
              " 'traje',\n",
              " 'No',\n",
              " 'visto',\n",
              " 'de',\n",
              " 'traje',\n",
              " 'Puro',\n",
              " 'corte',\n",
              " 'calle',\n",
              " ',',\n",
              " 'no',\n",
              " 'de',\n",
              " 'maquillaje',\n",
              " 'Pronto',\n",
              " 'coronamos',\n",
              " 'y',\n",
              " 'nos',\n",
              " 'vamo',\n",
              " \"'\",\n",
              " 'de',\n",
              " 'viaje',\n",
              " 'Tanto',\n",
              " 'hit',\n",
              " 'que',\n",
              " 'hago',\n",
              " 'que',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'culo',\n",
              " 'bajen',\n",
              " 'Ella',\n",
              " 'se',\n",
              " 'va',\n",
              " 'de',\n",
              " 'shopping',\n",
              " 'Sale',\n",
              " 'positivo',\n",
              " 'si',\n",
              " 'se',\n",
              " 'hace',\n",
              " 'el',\n",
              " 'doping',\n",
              " 'Baila',\n",
              " 'twerk',\n",
              " 'con',\n",
              " 'un',\n",
              " 'poco',\n",
              " 'de',\n",
              " 'popping',\n",
              " 'Los',\n",
              " 'fardos',\n",
              " 'en',\n",
              " 'el',\n",
              " 'bot√≠n',\n",
              " 'Si',\n",
              " 'quieren',\n",
              " 'letra',\n",
              " 'llamen',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'mi',\n",
              " 'booking',\n",
              " 'Generando',\n",
              " ',',\n",
              " 'sigo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'm√≠a',\n",
              " 'lowkey',\n",
              " 'Cooking',\n",
              " 'en',\n",
              " 'el',\n",
              " 'estudio',\n",
              " 'con',\n",
              " 'tu',\n",
              " 'woman',\n",
              " 'Tanto',\n",
              " 'whisky',\n",
              " ',',\n",
              " 'pisco',\n",
              " 'que',\n",
              " 'hasta',\n",
              " 'lo',\n",
              " \"'\",\n",
              " 'vecinos',\n",
              " 'toman',\n",
              " 'Si',\n",
              " 'se',\n",
              " 'tiran',\n",
              " 'pa',\n",
              " \"'\",\n",
              " 'aca',\n",
              " 'puede',\n",
              " 'que',\n",
              " 'la',\n",
              " 'arena',\n",
              " 'coman',\n",
              " 'Ja',\n",
              " ',',\n",
              " 'en',\n",
              " 'el',\n",
              " 'chanteo',\n",
              " 'titulado',\n",
              " 'sin',\n",
              " 'diploma',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Di',\n",
              " '-',\n",
              " 'dimelo',\n",
              " 'm√°',\n",
              " 'Ah',\n",
              " ',',\n",
              " 'pe',\n",
              " '-',\n",
              " 'peligrosa',\n",
              " 'Quiero',\n",
              " 'ver',\n",
              " 'como',\n",
              " 'perreando',\n",
              " 'me',\n",
              " 'acosa',\n",
              " 'Eso',\n",
              " 'de',\n",
              " 'atra',\n",
              " \"'\",\n",
              " 'con',\n",
              " 'el',\n",
              " 'Gucci',\n",
              " 'me',\n",
              " 'lo',\n",
              " 'roza',\n",
              " 'Tengo',\n",
              " 'tussi',\n",
              " 'del',\n",
              " 'naranjo',\n",
              " 'me',\n",
              " 'aburrio',\n",
              " 'el',\n",
              " 'rosa',\n",
              " 'Capaz',\n",
              " 'que',\n",
              " 'tosa',\n",
              " 'con',\n",
              " 'el',\n",
              " 'blunt',\n",
              " 'Sprite',\n",
              " 'con',\n",
              " 'Flemibron',\n",
              " 'Louis',\n",
              " 'Vuitton',\n",
              " ',',\n",
              " 'le',\n",
              " 'quito',\n",
              " 'la',\n",
              " 'polera',\n",
              " 'Champion',\n",
              " 'A',\n",
              " 'tu',\n",
              " 'pretendiente',\n",
              " 'con',\n",
              " 'la',\n",
              " 'fory',\n",
              " 'lo',\n",
              " 'espanto',\n",
              " 'Puro',\n",
              " 'perro',\n",
              " ',',\n",
              " 'le',\n",
              " 'doy',\n",
              " 'de',\n",
              " 'comer',\n",
              " 'Champion',\n",
              " 'Dog',\n",
              " 'Ese',\n",
              " 'toto',\n",
              " 'lo',\n",
              " 'corono',\n",
              " 'yo',\n",
              " 'La',\n",
              " 'movie',\n",
              " 'en',\n",
              " 'play',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stop',\n",
              " 'Flow',\n",
              " 'de',\n",
              " 'sobra',\n",
              " 'no',\n",
              " 'hay',\n",
              " 'stock',\n",
              " 'Me',\n",
              " 'la',\n",
              " 'topo',\n",
              " 'en',\n",
              " 'la',\n",
              " 'disco',\n",
              " 'queda',\n",
              " 'en',\n",
              " 'shock',\n",
              " 'My',\n",
              " 'love',\n",
              " ',',\n",
              " 'rica',\n",
              " 'en',\n",
              " 'las',\n",
              " 'redes',\n",
              " 'y',\n",
              " 'en',\n",
              " 'persona',\n",
              " 'No',\n",
              " 'usa',\n",
              " 'Photoshop',\n",
              " 'La',\n",
              " 'llevo',\n",
              " 'a',\n",
              " 'comprar',\n",
              " 'blone',\n",
              " \"'\",\n",
              " 'al',\n",
              " 'growshop',\n",
              " 'En',\n",
              " 'ropa',\n",
              " 'interior',\n",
              " 'los',\n",
              " 'do',\n",
              " \"'\",\n",
              " 'Me',\n",
              " 'roza',\n",
              " 'su',\n",
              " 'vicky',\n",
              " 'con',\n",
              " 'mi',\n",
              " 'boxer',\n",
              " 'Top',\n",
              " 'Dimelo',\n",
              " 'm√°',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'cri',\n",
              " 'minal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Dimelo',\n",
              " 'm√°',\n",
              " 'Ando',\n",
              " 'en',\n",
              " 'busca',\n",
              " 'de',\n",
              " 'una',\n",
              " 'criminal',\n",
              " '(',\n",
              " 'ah',\n",
              " ',',\n",
              " 'ah',\n",
              " ')',\n",
              " 'Esa',\n",
              " 'que',\n",
              " 'el',\n",
              " 'gatillo',\n",
              " 'le',\n",
              " 'gusta',\n",
              " 'jalar',\n",
              " '(',\n",
              " 'rata',\n",
              " '-',\n",
              " 'ta',\n",
              " ')',\n",
              " 'Que',\n",
              " 'le',\n",
              " 'guste',\n",
              " 'flotar',\n",
              " 'y',\n",
              " 'fumar',\n",
              " 'Tussi',\n",
              " ',',\n",
              " 'keta',\n",
              " 'pura',\n",
              " 'quiere',\n",
              " \"'\",\n",
              " 'mezclar',\n",
              " 'Marcianeke',\n",
              " ',',\n",
              " 'Pailita',\n",
              " 'Young',\n",
              " 'Varas']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = get_tokens(text)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPbgTvAW-stF"
      },
      "source": [
        "**Describa cu√°les fueron sus supuestos para realizar la tokenizaci√≥n y compare sus tokens con los entregados por la librer√≠a nltk en el bloque de c√≥digo de m√°s abajo.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGQ7CJy3-3aH"
      },
      "source": [
        "Para obtener los tokens se hicieron 2 supuestos: un token es un conjunto de caracteres que se encuentran entre:\n",
        "\n",
        "- El principio, final y/o alg√∫n espacio (salto de l√≠nea, espacio en blanco, etc.).\n",
        "\n",
        "- Alg√∫n car√°cter que no sea ni un n√∫mero, letra, gui√≥n bajo o alg√∫n tipo de espacio.\n",
        "\n",
        "En el segundo caso, adem√°s de definir un token, dicho car√°cter se cuenta tambi√©n como un token aparte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYtmAXTr9KXK",
        "outputId": "1b0ad0bd-151d-4417-89da-b6fd7345fb53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "¬øEl resultado es id√©ntico?: True\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import wordpunct_tokenize \n",
        "nltk_tokens = wordpunct_tokenize(text)\n",
        "print(f\"¬øEl resultado es id√©ntico?: {tokens == nltk_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5QKlXAZwN1L"
      },
      "source": [
        "**Ejercicio 2 - *Stopwords y Stemming*** \n",
        "\n",
        "Considere el siguiente corpus:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sEp83zESwb2j"
      },
      "outputs": [],
      "source": [
        "dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmjdlJWuyS2E"
      },
      "source": [
        "Dise√±e una funci√≥n **`get_vocab()`** que extraiga los tokens de este corpus solamente tokenizando. Puede utilizar la funci√≥n del Ejercicio 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UudC-b6TzZgw"
      },
      "outputs": [],
      "source": [
        "def get_vocab(dataset: list[str]) -> list[str]:\n",
        "  \"\"\"Entrega una lista con el vocab contenido en dataset\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  dataset : list[str]\n",
        "      Corpus del que se obtendr√° el vocab\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  list[str]\n",
        "      Vocab del corpus\n",
        "  \"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  \n",
        "  vocab = [get_tokens(doc) for doc in dataset]\n",
        "  vocab = reduce(lambda vocab1, vocab2: vocab1 + vocab2, vocab)\n",
        "  return list(dict.fromkeys(vocab)) # Diccionarios preservan el orden. Es m√°s f√°cil con un 'set'\n",
        "\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-m32IoNmSwM"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNzPKiAx0Aa1",
        "outputId": "5a9ffce1-93e6-4111-9879-eb0916f0922a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['I',\n",
              " 'like',\n",
              " 'human',\n",
              " 'languages',\n",
              " 'programming',\n",
              " 'Spanish',\n",
              " 'is',\n",
              " 'my',\n",
              " 'favorite',\n",
              " 'language']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = get_vocab(dataset)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZLV2hWf9FN7"
      },
      "source": [
        "***Resultado esperado***: \n",
        "<table>\n",
        "    <tr> \n",
        "        <td>['favorite',\n",
        " 'Spanish',\n",
        " 'language',\n",
        " 'I',\n",
        " 'like',\n",
        " 'programming',\n",
        " 'languages',\n",
        " 'my',\n",
        " 'human',\n",
        " 'is'] </td> \n",
        "    </tr>\n",
        "</table> "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3KB0fL2zk2v"
      },
      "source": [
        "Ahora dise√±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci√≥n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario actualizado. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY7g67Ml0aby"
      },
      "source": [
        "Para las stopwords se agregaron palabras comunes en ingl√©s, que considera algunos art√≠culos, pronombres, preposiciones y conjunciones.\n",
        "\n",
        "En cu√°nto al stemming, por simplicidad se ha decidido implementar algunas reglas que alteran el final de una palabra s√≥lamente por medio de la eliminaci√≥n de caracteres. Las reglas implementadas corresponden a:\n",
        "\n",
        "- Si una palabra termina en SSES, se elimina ES.\n",
        "- Si una palabra termina en IES, se elimina ES.\n",
        "- Si una palabra termina en ING, se eliminan estos 3 caracteres.\n",
        "- Si una palabra termina en S, se elimina este car√°cter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CwQS8lcLJczI"
      },
      "outputs": [],
      "source": [
        "def pre_processing(vocab: list[str]) -> list[str]:\n",
        "  \"\"\"Pre-procesamiento de un vocab, que involucra stemming y stopwords\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  vocab : list[str]\n",
        "      Vocab a ser pre-procesado\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  list[str]\n",
        "      Vocab sin las stopwords y con stemming aplicado\n",
        "  \"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  \n",
        "  stopwords = [\n",
        "      \"I\",\n",
        "      \"you\",\n",
        "      \"he\",\n",
        "      \"she\",\n",
        "      \"it\",\n",
        "      \"they\",\n",
        "      \"to\",\n",
        "      \"into\",\n",
        "      \"on\",\n",
        "      \"at\",\n",
        "      \"for\",\n",
        "      \"by\",\n",
        "      \"my\",\n",
        "      \"a\",\n",
        "      \"an\",\n",
        "      \"the\",\n",
        "      \"but\",\n",
        "      \"yet\",\n",
        "      \"and\",\n",
        "      \"or\",\n",
        "      \"so\"\n",
        "  ]\n",
        "\n",
        "  preprocessed_vocab = filter(lambda string: string not in stopwords, vocab)\n",
        "\n",
        "  stemming_pattern = r\"(?<=ss)es|(?<=i)es|(?<=\\w)ing$|(?<=\\w)s$\"\n",
        "  preprocessed_vocab = list( map(lambda string: re.sub(stemming_pattern, \"\", string), preprocessed_vocab) )\n",
        "\n",
        "  return preprocessed_vocab \n",
        "\n",
        "  ### Aqu√≠ termina tu c√≥digo ###    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onOSuS-_mL2F",
        "outputId": "d5d15bcc-0f4a-4c15-8504-9c3bdc86edda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['like',\n",
              " 'human',\n",
              " 'language',\n",
              " 'programm',\n",
              " 'Spanish',\n",
              " 'i',\n",
              " 'favorite',\n",
              " 'language']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab = pre_processing(vocab)\n",
        "vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65IwHx11uA75"
      },
      "source": [
        "**Ejercicio 3 - *Bag of Words* üê∂üêà** \n",
        "\n",
        "Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:\n",
        "\n",
        "**disclaimer: El orden de los resultados pueden variar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Rh-utMuozhsK"
      },
      "outputs": [],
      "source": [
        "d0 = 'El perro se come la comida y despu√©s se duerme'\n",
        "d1 = 'El perro se despierta y despu√©s empieza a ladrar'\n",
        "d2 = 'El perro ladra y despu√©s se come la comida'\n",
        "d3 = 'El gato se come la comida y despu√©s se duerme'\n",
        "d4 = 'El gato se despierta y despu√©s empieza a maullar'\n",
        "d5 = 'El gato maulla y despu√©s se come la comida'\n",
        "dataset = [d0, d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH7ne8C6ltvE"
      },
      "source": [
        "El objetivo de este ejercicio es determinar cu√°les de  los documentos entregados son los m√°s similares entre s√≠. Para ello utilizaremos la t√©cnica TF-IDF. \n",
        "\n",
        "Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num√©ricos. La representaci√≥n m√°s simple vista en clases es el **Bag of Words**, m√©todo mediante el cu√°l se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n",
        "\n",
        "Implemente la funci√≥n **`bag_of_words()`**, que reciba como input un arreglo de documentos y devuelva un pandas dataframe con la representaci√≥n Bag of Words de los documentos entregados. En esta representaci√≥n las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el bow de un determinado documento.\n",
        "\n",
        "\n",
        "Por ejemplo para el siguiente dataset: \n",
        "\n",
        "```\n",
        "dataset = ['El perro ladra', 'El perro come']\n",
        "```\n",
        "\n",
        "Debiese entregarnos lo siguiente:\n",
        "\n",
        "\n",
        "|   | el | perro | ladra | come |\n",
        "|---|----|-------|------|-------|\n",
        "| 0 | 1  | 1     | 1    | 0     |\n",
        "| 1 | 1  | 1     | 0    | 1     |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kXDMAyFmnq5j"
      },
      "outputs": [],
      "source": [
        "def bag_of_words(dataset: list[str]) -> pd.DataFrame:\n",
        "  \"\"\"Entrega bag of words a partir de una lista de documentos\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  dataset : list[str]\n",
        "      Lista con documentos\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  pd.DataFrame\n",
        "      Bag of Words de los documentos\n",
        "  \"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  \n",
        "  cols = get_vocab(dataset)\n",
        "  data = [Counter(d.split()) for d in dataset]\n",
        "  df_bow = pd.DataFrame(data, columns=cols).fillna(0)\n",
        "  return df_bow.astype(np.uint8)\n",
        "\n",
        "  ### Aqu√≠ termina tu c√≥digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okfo-nEQmW1R"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "T_Kk9GwCoDW8",
        "outputId": "c269dff2-5adb-4a4e-b6c2-7e5c5f9b11cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>perro</th>\n",
              "      <th>se</th>\n",
              "      <th>come</th>\n",
              "      <th>la</th>\n",
              "      <th>comida</th>\n",
              "      <th>y</th>\n",
              "      <th>despu√©s</th>\n",
              "      <th>duerme</th>\n",
              "      <th>despierta</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>ladra</th>\n",
              "      <th>gato</th>\n",
              "      <th>maullar</th>\n",
              "      <th>maulla</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   El  perro  se  come  la  comida  y  despu√©s  duerme  despierta  empieza  a  \\\n",
              "0   1      1   2     1   1       1  1        1       1          0        0  0   \n",
              "1   1      1   1     0   0       0  1        1       0          1        1  1   \n",
              "2   1      1   1     1   1       1  1        1       0          0        0  0   \n",
              "3   1      0   2     1   1       1  1        1       1          0        0  0   \n",
              "4   1      0   1     0   0       0  1        1       0          1        1  1   \n",
              "5   1      0   1     1   1       1  1        1       0          0        0  0   \n",
              "\n",
              "   ladrar  ladra  gato  maullar  maulla  \n",
              "0       0      0     0        0       0  \n",
              "1       1      0     0        0       0  \n",
              "2       0      1     0        0       0  \n",
              "3       0      0     1        0       0  \n",
              "4       0      0     1        1       0  \n",
              "5       0      0     1        0       1  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset_bow = bag_of_words(dataset)\n",
        "dataset_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeR5ADGz-MPa"
      },
      "source": [
        "***Resultado esperado***: \n",
        "\n",
        "|    | El | perro | se | come | la | comida | y | despu√©s | duerme | despierta | empieza | a | ladrar | ladra | gato | maullar | maulla |\n",
        "|----|---:|------:|---:|-----:|---:|-------:|--:|--------:|-------:|----------:|--------:|--:|-------:|------:|-----:|--------:|-------:|\n",
        "| d0 |  1 |     1 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    0 |       0 |      0 |\n",
        "| d1 |  1 |     1 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      1 |     0 |    0 |       0 |      0 |\n",
        "| d2 |  1 |     1 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     1 |    0 |       0 |      0 |\n",
        "| d3 |  1 |     0 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      0 |\n",
        "| d4 |  1 |     0 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      0 |     0 |    1 |       1 |      0 |\n",
        "| d5 |  1 |     0 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      1 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4OXMz7opWcd"
      },
      "source": [
        "**Ejercicio 4 - *Calcular TF*:** Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m√°xima frecuencia ${max_i({\\text{tf}_{i,j})}}$, donde\n",
        "i corresponde al √≠ndice de las filas (bow) y j al de las columnas (palabras). Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca m√°s veces en ese vector. \n",
        "\n",
        "\n",
        "$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xWE16xhBpswc"
      },
      "outputs": [],
      "source": [
        "def calc_tf(dataset_bow: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Obtiene la m√©trica Term Frequency a partir de bag of words\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset_bow : pd.DataFrame\n",
        "        Bag of words al que se le calcurar√° TF\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Dataframe con la m√©trica TF\n",
        "    \"\"\"\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "    \n",
        "    tf = dataset_bow.div(dataset_bow.max(axis=\"columns\"), axis=\"index\")\n",
        "    return tf\n",
        "    \n",
        "    ### Aqu√≠ termina tu c√≥digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZQPZe3JmYqy"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "YQ2h8jEYp4nZ",
        "outputId": "fcf01588-0338-4055-bb8c-7a24b640a491"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>perro</th>\n",
              "      <th>se</th>\n",
              "      <th>come</th>\n",
              "      <th>la</th>\n",
              "      <th>comida</th>\n",
              "      <th>y</th>\n",
              "      <th>despu√©s</th>\n",
              "      <th>duerme</th>\n",
              "      <th>despierta</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>ladra</th>\n",
              "      <th>gato</th>\n",
              "      <th>maullar</th>\n",
              "      <th>maulla</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    El  perro   se  come   la  comida    y  despu√©s  duerme  despierta  \\\n",
              "0  0.5    0.5  1.0   0.5  0.5     0.5  0.5      0.5     0.5        0.0   \n",
              "1  1.0    1.0  1.0   0.0  0.0     0.0  1.0      1.0     0.0        1.0   \n",
              "2  1.0    1.0  1.0   1.0  1.0     1.0  1.0      1.0     0.0        0.0   \n",
              "3  0.5    0.0  1.0   0.5  0.5     0.5  0.5      0.5     0.5        0.0   \n",
              "4  1.0    0.0  1.0   0.0  0.0     0.0  1.0      1.0     0.0        1.0   \n",
              "5  1.0    0.0  1.0   1.0  1.0     1.0  1.0      1.0     0.0        0.0   \n",
              "\n",
              "   empieza    a  ladrar  ladra  gato  maullar  maulla  \n",
              "0      0.0  0.0     0.0    0.0   0.0      0.0     0.0  \n",
              "1      1.0  1.0     1.0    0.0   0.0      0.0     0.0  \n",
              "2      0.0  0.0     0.0    1.0   0.0      0.0     0.0  \n",
              "3      0.0  0.0     0.0    0.0   0.5      0.0     0.0  \n",
              "4      1.0  1.0     0.0    0.0   1.0      1.0     0.0  \n",
              "5      0.0  0.0     0.0    0.0   1.0      0.0     1.0  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf = calc_tf(dataset_bow)\n",
        "tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOzdRwx9_UMM"
      },
      "source": [
        "***Resultado esperado***: \n",
        "\n",
        "|    |  El | perro |  se | come |  la | comida |   y | despu√©s | duerme | despierta | empieza |   a | ladrar | ladra | gato | maullar | maulla |\n",
        "|----|----:|------:|----:|-----:|----:|-------:|----:|--------:|-------:|----------:|--------:|----:|-------:|------:|-----:|--------:|-------:|\n",
        "| d0 | 0.5 |   0.5 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d1 | 1.0 |   1.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    1.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d2 | 1.0 |   1.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   1.0 |  0.0 |     0.0 |    0.0 |\n",
        "| d3 | 0.5 |   0.0 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.5 |     0.0 |    0.0 |\n",
        "| d4 | 1.0 |   0.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    0.0 |   0.0 |  1.0 |     1.0 |    0.0 |\n",
        "| d5 | 1.0 |   0.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  1.0 |     0.0 |    1.0 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqgW4Ni4t0xC"
      },
      "source": [
        "**Ejercicio 5 - *Calcular IDF***\n",
        "\n",
        "\n",
        "Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n",
        "\n",
        "Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ n√∫mero de documentos y $n_i = $ N√∫mero de documentos que contienen la palabra $t_i$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "thhDY1-Ht6T5"
      },
      "outputs": [],
      "source": [
        "def calc_idf(dataset_bow: pd.DataFrame) -> dict[str, float]:\n",
        "    \"\"\"Calcula la m√©trica Inverse Document Frequency sobre un bag of words\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dataset_bow : pd.DataFrame\n",
        "        Bag of words al que se le calcular√° IDF\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    dict[str, float]\n",
        "        Diccionario con la m√©trica IDF para cada token\n",
        "    \"\"\"\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "\n",
        "    count = dataset_bow.agg(np.count_nonzero)\n",
        "    idf = np.log10(dataset_bow.shape[0]/count)\n",
        "    return dict(idf)\n",
        "\n",
        "    ### Aqu√≠ termina tu c√≥digo ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR_j3pYemcAc"
      },
      "source": [
        "***Test:***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro-OMGpduC0R",
        "outputId": "924ae370-1b35-4d57-9757-3a84ffa7f6f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'El': 0.0,\n",
              " 'perro': 0.3010299956639812,\n",
              " 'se': 0.0,\n",
              " 'come': 0.17609125905568124,\n",
              " 'la': 0.17609125905568124,\n",
              " 'comida': 0.17609125905568124,\n",
              " 'y': 0.0,\n",
              " 'despu√©s': 0.0,\n",
              " 'duerme': 0.47712125471966244,\n",
              " 'despierta': 0.47712125471966244,\n",
              " 'empieza': 0.47712125471966244,\n",
              " 'a': 0.47712125471966244,\n",
              " 'ladrar': 0.7781512503836436,\n",
              " 'ladra': 0.7781512503836436,\n",
              " 'gato': 0.3010299956639812,\n",
              " 'maullar': 0.7781512503836436,\n",
              " 'maulla': 0.7781512503836436}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idf = calc_idf(dataset_bow)\n",
        "idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ioy_HicQDr-a"
      },
      "source": [
        "***Resultado esperado***: \n",
        "\n",
        "```python\n",
        "{'El': 0.0, \n",
        " 'a': 0.47712125471966244,\n",
        " 'come': 0.17609125905568124,\n",
        " 'comida': 0.17609125905568124,\n",
        " 'despierta': 0.47712125471966244,\n",
        " 'despu√©s': 0.0,\n",
        " 'duerme': 0.47712125471966244,\n",
        " 'empieza': 0.47712125471966244,\n",
        " 'gato': 0.3010299956639812,\n",
        " 'la': 0.17609125905568124,\n",
        " 'ladra': 0.7781512503836436,\n",
        " 'ladrar': 0.7781512503836436,\n",
        " 'maulla': 0.7781512503836436,\n",
        " 'maullar': 0.7781512503836436,\n",
        " 'perro': 0.3010299956639812,\n",
        " 'se': 0.0,\n",
        " 'y': 0.0}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzKAzJtSJ7gx"
      },
      "source": [
        "Puede notar el bajo puntaje otorgado a las palabras que m√°s se repiten! üòÆ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D17lm6l9uJPo"
      },
      "source": [
        "**Ejercicio 6 - *Calcular TF-IDF & concluir similitud de documentos.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc7FTQ19Kcwo"
      },
      "source": [
        "Programe la funci√≥n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "9knMl0KguMwo"
      },
      "outputs": [],
      "source": [
        "def calc_tf_idf(tf: pd.DataFrame, idf: dict[str, float]) -> pd.DataFrame:\n",
        "    \"\"\"Calcula la m√©trica TF-IDF\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tf : pd.DataFrame\n",
        "        M√©trica TF de un BoW\n",
        "    idf : dict[str, float]\n",
        "        M√©trica IDF del mismo BoW de TF\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        M√©trica TF-IDF\n",
        "    \"\"\"\n",
        "    ### Aqu√≠ inicia tu c√≥digo ###\n",
        "\n",
        "    tf_idf = tf.mul(idf)\n",
        "    return tf_idf\n",
        "\n",
        "    ### Aqu√≠ termina tu c√≥digo ### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRzIr1nQmepp"
      },
      "source": [
        "***Test.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "H8z6jaq2uPEo",
        "outputId": "4413ac47-c154-4a3a-a5f0-8f9ba6ee7bae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>El</th>\n",
              "      <th>perro</th>\n",
              "      <th>se</th>\n",
              "      <th>come</th>\n",
              "      <th>la</th>\n",
              "      <th>comida</th>\n",
              "      <th>y</th>\n",
              "      <th>despu√©s</th>\n",
              "      <th>duerme</th>\n",
              "      <th>despierta</th>\n",
              "      <th>empieza</th>\n",
              "      <th>a</th>\n",
              "      <th>ladrar</th>\n",
              "      <th>ladra</th>\n",
              "      <th>gato</th>\n",
              "      <th>maullar</th>\n",
              "      <th>maulla</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150515</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.238561</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.088046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.238561</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150515</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.477121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.778151</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.176091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.301030</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.778151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    El     perro   se      come        la    comida    y  despu√©s    duerme  \\\n",
              "0  0.0  0.150515  0.0  0.088046  0.088046  0.088046  0.0      0.0  0.238561   \n",
              "1  0.0  0.301030  0.0  0.000000  0.000000  0.000000  0.0      0.0  0.000000   \n",
              "2  0.0  0.301030  0.0  0.176091  0.176091  0.176091  0.0      0.0  0.000000   \n",
              "3  0.0  0.000000  0.0  0.088046  0.088046  0.088046  0.0      0.0  0.238561   \n",
              "4  0.0  0.000000  0.0  0.000000  0.000000  0.000000  0.0      0.0  0.000000   \n",
              "5  0.0  0.000000  0.0  0.176091  0.176091  0.176091  0.0      0.0  0.000000   \n",
              "\n",
              "   despierta   empieza         a    ladrar     ladra      gato   maullar  \\\n",
              "0   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "1   0.477121  0.477121  0.477121  0.778151  0.000000  0.000000  0.000000   \n",
              "2   0.000000  0.000000  0.000000  0.000000  0.778151  0.000000  0.000000   \n",
              "3   0.000000  0.000000  0.000000  0.000000  0.000000  0.150515  0.000000   \n",
              "4   0.477121  0.477121  0.477121  0.000000  0.000000  0.301030  0.778151   \n",
              "5   0.000000  0.000000  0.000000  0.000000  0.000000  0.301030  0.000000   \n",
              "\n",
              "     maulla  \n",
              "0  0.000000  \n",
              "1  0.000000  \n",
              "2  0.000000  \n",
              "3  0.000000  \n",
              "4  0.000000  \n",
              "5  0.778151  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf = calc_tf_idf(tf, idf)\n",
        "tf_idf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBG2qfwv_6HK"
      },
      "source": [
        "***Resultado esperado***: \n",
        "\n",
        "|    |  El |    perro |  se |     come |       la |   comida |   y | despu√©s |   duerme | despierta |  empieza |        a |   ladrar |    ladra |     gato |  maullar |   maulla |\n",
        "|----|----:|---------:|----:|---------:|---------:|---------:|----:|--------:|---------:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n",
        "| d0 | 0.0 | 0.150515 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d1 | 0.0 | 0.301030 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.778151 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d2 | 0.0 | 0.301030 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.778151 | 0.000000 | 0.000000 | 0.000000 |\n",
        "| d3 | 0.0 | 0.000000 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.150515 | 0.000000 | 0.000000 |\n",
        "| d4 | 0.0 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.000000 | 0.000000 | 0.301030 | 0.778151 | 0.000000 |\n",
        "| d5 | 0.0 | 0.000000 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.301030 | 0.000000 | 0.778151 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmVlbpzMp5NU"
      },
      "source": [
        "Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser√° una matriz sim√©trica. Implemente la funci√≥n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos vectores. Concluya cu√°les son los dos documentos m√°s similares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HEgUtgBkQAae"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(v1: pd.Series, v2: pd.Series) -> float:\n",
        "  \"\"\"Calcula la similitud coseno entre todos los documentos de un corpus\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  v1 : pd.Series\n",
        "      Primer vector de caracter√≠sticas\n",
        "  v2 : pd.Series\n",
        "      Segundo vector de caracter√≠sticas\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  float\n",
        "      Similitud coseno entre todos los documentos de un corpus\n",
        "  \"\"\"\n",
        "  ### Aqu√≠ inicia tu c√≥digo ###\n",
        "  \n",
        "  similarity = (v1 @ v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "  return similarity\n",
        "\n",
        "  ### Aqu√≠ termina tu c√≥digo ### \n",
        "\n",
        "similarity_matrix = np.zeros((6,6))\n",
        "for i, v1 in enumerate(tf_idf.index.values):\n",
        "  for j, v2 in enumerate(tf_idf.index.values):\n",
        "      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n",
        "      similarity_matrix[i][j] = similarity\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.120324</td>\n",
              "      <td>0.322344</td>\n",
              "      <td>0.779670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.163283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.120324</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.086865</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.495213</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.322344</td>\n",
              "      <td>0.086865</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.163283</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.779670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.163283</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.120324</td>\n",
              "      <td>0.322344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.495213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.120324</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.086865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.163283</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117877</td>\n",
              "      <td>0.322344</td>\n",
              "      <td>0.086865</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3         4         5\n",
              "0  1.000000  0.120324  0.322344  0.779670  0.000000  0.163283\n",
              "1  0.120324  1.000000  0.086865  0.000000  0.495213  0.000000\n",
              "2  0.322344  0.086865  1.000000  0.163283  0.000000  0.117877\n",
              "3  0.779670  0.000000  0.163283  1.000000  0.120324  0.322344\n",
              "4  0.000000  0.495213  0.000000  0.120324  1.000000  0.086865\n",
              "5  0.163283  0.000000  0.117877  0.322344  0.086865  1.000000"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(similarity_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Los documentos m√°s similiares en base a la similaridad de coseno son los documentos **d3** y **d0**, con una similaridad de 0.779."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
